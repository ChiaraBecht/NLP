{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "from flair.embeddings import SentenceTransformerDocumentEmbeddings\n",
    "from flair.embeddings import StackedEmbeddings\n",
    "from flair.data import Sentence\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading vocab.txt: 100%|██████████| 223k/223k [00:00<00:00, 620kB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Sentence: \"The grass is green .\"]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init embedding\n",
    "# source: https://huggingface.co/gsarti/scibert-nli\n",
    "#sci_embedding = SentenceTransformerDocumentEmbeddings(\"allenai/scibert_scivocab_uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import SentenceTransformerDocumentEmbeddings\n",
    "# source: https://huggingface.co/pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb\n",
    "# init embedding\n",
    "bio_embedding = SentenceTransformerDocumentEmbeddings(\"pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two sentence embeddings\n",
    "#combined = [bio_embedding, sci_embedding]\n",
    "#stack = StackedEmbeddings(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-04 19:10:37,680 Reading data from /students/2022-2023/master/spacey/chiara/Meta-knowledge_GENIA_corpus/corpus\n",
      "2023-02-04 19:10:37,681 Train: /students/2022-2023/master/spacey/chiara/Meta-knowledge_GENIA_corpus/corpus/train.csv\n",
      "2023-02-04 19:10:37,682 Dev: /students/2022-2023/master/spacey/chiara/Meta-knowledge_GENIA_corpus/corpus/dev.csv\n",
      "2023-02-04 19:10:37,682 Test: /students/2022-2023/master/spacey/chiara/Meta-knowledge_GENIA_corpus/corpus/test.csv\n",
      "Corpus: 2374 train + 607 dev + 607 test sentences\n"
     ]
    }
   ],
   "source": [
    "# Load tagged corpus\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = r'/students/2022-2023/master/spacey/chiara/Meta-knowledge_GENIA_corpus/corpus/'\n",
    "#print(data_folder)\n",
    "column_name_map = {0: \"text\", 1:\"label\"}  \n",
    "label_type = \"label\" \n",
    "\n",
    "corpus = CSVClassificationCorpus(data_folder, \n",
    "                                        column_name_map, \n",
    "                                        skip_header=True, \n",
    "                                        delimiter=\"|\",\n",
    "                                        train_file= 'train.csv',\n",
    "                                        dev_file= 'dev.csv',\n",
    "                                        test_file= 'test.csv', \n",
    "                                        label_type=label_type)\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-04 19:10:41,504 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2374it [00:01, 2057.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-04 19:10:42,662 Dictionary created for label 'label' with 4 values: L2 (seen 1068 times), L3 (seen 1000 times), L1 (seen 306 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_dict = corpus.make_label_dictionary(label_type=label_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = TextClassifier(bio_embedding, label_dictionary = label_dict, label_type = label_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-04 19:56:30,283 ----------------------------------------------------------------------------------------------------\n",
      "2023-02-04 19:56:30,284 Model: \"TextClassifier(\n",
      "  (decoder): Linear(in_features=768, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (document_embeddings): SentenceTransformerDocumentEmbeddings(\n",
      "    (model): SentenceTransformer(\n",
      "      (0): Transformer({'max_seq_length': 100, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "      (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      "    )\n",
      "  )\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2023-02-04 19:56:30,285 ----------------------------------------------------------------------------------------------------\n",
      "2023-02-04 19:56:30,287 Corpus: \"Corpus: 2374 train + 607 dev + 607 test sentences\"\n",
      "2023-02-04 19:56:30,288 ----------------------------------------------------------------------------------------------------\n",
      "2023-02-04 19:56:30,288 Parameters:\n",
      "2023-02-04 19:56:30,289  - learning_rate: \"0.100000\"\n",
      "2023-02-04 19:56:30,290  - mini_batch_size: \"32\"\n",
      "2023-02-04 19:56:30,290  - patience: \"3\"\n",
      "2023-02-04 19:56:30,291  - anneal_factor: \"0.5\"\n",
      "2023-02-04 19:56:30,292  - max_epochs: \"4\"\n",
      "2023-02-04 19:56:30,292  - shuffle: \"True\"\n",
      "2023-02-04 19:56:30,293  - train_with_dev: \"False\"\n",
      "2023-02-04 19:56:30,293  - batch_growth_annealing: \"False\"\n",
      "2023-02-04 19:56:30,294 ----------------------------------------------------------------------------------------------------\n",
      "2023-02-04 19:56:30,295 Model training base path: \"classifier\"\n",
      "2023-02-04 19:56:30,295 ----------------------------------------------------------------------------------------------------\n",
      "2023-02-04 19:56:30,296 Device: cpu\n",
      "2023-02-04 19:56:30,296 ----------------------------------------------------------------------------------------------------\n",
      "2023-02-04 19:56:30,297 Embeddings storage mode: cpu\n",
      "2023-02-04 19:56:30,298 ----------------------------------------------------------------------------------------------------\n",
      "2023-02-04 19:56:50,569 epoch 1 - iter 7/75 - loss 0.02755919 - samples/sec: 11.30 - lr: 0.100000\n",
      "2023-02-04 19:57:08,679 epoch 1 - iter 14/75 - loss 0.02257609 - samples/sec: 12.44 - lr: 0.100000\n",
      "2023-02-04 19:57:26,636 epoch 1 - iter 21/75 - loss 0.02143111 - samples/sec: 12.54 - lr: 0.100000\n",
      "2023-02-04 19:57:45,296 epoch 1 - iter 28/75 - loss 0.01990783 - samples/sec: 12.07 - lr: 0.100000\n",
      "2023-02-04 19:58:04,387 epoch 1 - iter 35/75 - loss 0.01825378 - samples/sec: 11.80 - lr: 0.100000\n",
      "2023-02-04 19:58:23,303 epoch 1 - iter 42/75 - loss 0.01738739 - samples/sec: 11.91 - lr: 0.100000\n",
      "2023-02-04 19:58:40,362 epoch 1 - iter 49/75 - loss 0.02078996 - samples/sec: 13.20 - lr: 0.100000\n",
      "2023-02-04 19:58:58,025 epoch 1 - iter 56/75 - loss 0.01826496 - samples/sec: 12.75 - lr: 0.100000\n",
      "2023-02-04 19:59:16,055 epoch 1 - iter 63/75 - loss 0.01626970 - samples/sec: 12.49 - lr: 0.100000\n",
      "2023-02-04 19:59:33,753 epoch 1 - iter 70/75 - loss 0.01466214 - samples/sec: 12.72 - lr: 0.100000\n",
      "2023-02-04 19:59:44,271 ----------------------------------------------------------------------------------------------------\n",
      "2023-02-04 19:59:44,272 EPOCH 1 done: loss 0.0138 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:48<00:00,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-04 20:00:32,972 Evaluating as a multi-label problem: False\n",
      "2023-02-04 20:00:32,986 DEV : loss 0.05955692008137703 - f1-score (micro avg)  0.7183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-04 20:00:33,258 BAD EPOCHS (no improvement): 0\n",
      "2023-02-04 20:00:33,262 saving best model\n",
      "2023-02-04 20:00:37,038 ----------------------------------------------------------------------------------------------------\n",
      "2023-02-04 20:00:55,144 epoch 2 - iter 7/75 - loss 0.04694781 - samples/sec: 12.44 - lr: 0.100000\n",
      "2023-02-04 20:01:13,930 epoch 2 - iter 14/75 - loss 0.03636112 - samples/sec: 11.99 - lr: 0.100000\n",
      "2023-02-04 20:01:32,522 epoch 2 - iter 21/75 - loss 0.03327156 - samples/sec: 12.11 - lr: 0.100000\n",
      "2023-02-04 20:01:51,198 epoch 2 - iter 28/75 - loss 0.03166892 - samples/sec: 12.06 - lr: 0.100000\n",
      "2023-02-04 20:02:09,398 epoch 2 - iter 35/75 - loss 0.03098663 - samples/sec: 12.37 - lr: 0.100000\n",
      "2023-02-04 20:02:28,008 epoch 2 - iter 42/75 - loss 0.03026787 - samples/sec: 12.10 - lr: 0.100000\n",
      "2023-02-04 20:02:46,432 epoch 2 - iter 49/75 - loss 0.02939629 - samples/sec: 12.22 - lr: 0.100000\n",
      "2023-02-04 20:03:04,717 epoch 2 - iter 56/75 - loss 0.02834384 - samples/sec: 12.52 - lr: 0.100000\n",
      "2023-02-04 20:03:22,756 epoch 2 - iter 63/75 - loss 0.02762778 - samples/sec: 12.48 - lr: 0.100000\n",
      "2023-02-04 20:03:40,975 epoch 2 - iter 70/75 - loss 0.02693535 - samples/sec: 12.36 - lr: 0.100000\n",
      "2023-02-04 20:03:51,853 ----------------------------------------------------------------------------------------------------\n",
      "2023-02-04 20:03:51,854 EPOCH 2 done: loss 0.0268 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:47<00:00,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-04 20:04:39,439 Evaluating as a multi-label problem: False\n",
      "2023-02-04 20:04:39,453 DEV : loss 0.027069251984357834 - f1-score (micro avg)  0.5486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-04 20:04:39,725 BAD EPOCHS (no improvement): 1\n",
      "2023-02-04 20:04:39,730 ----------------------------------------------------------------------------------------------------\n",
      "2023-02-04 20:04:57,670 epoch 3 - iter 7/75 - loss 0.02221184 - samples/sec: 12.55 - lr: 0.100000\n",
      "2023-02-04 20:05:16,360 epoch 3 - iter 14/75 - loss 0.02285654 - samples/sec: 12.05 - lr: 0.100000\n",
      "2023-02-04 20:05:34,636 epoch 3 - iter 21/75 - loss 0.02275524 - samples/sec: 12.32 - lr: 0.100000\n",
      "2023-02-04 20:05:53,193 epoch 3 - iter 28/75 - loss 0.02205199 - samples/sec: 12.34 - lr: 0.100000\n",
      "2023-02-04 20:06:11,790 epoch 3 - iter 35/75 - loss 0.02170017 - samples/sec: 12.11 - lr: 0.100000\n",
      "2023-02-04 20:06:30,649 epoch 3 - iter 42/75 - loss 0.02220734 - samples/sec: 11.94 - lr: 0.100000\n",
      "2023-02-04 20:06:49,313 epoch 3 - iter 49/75 - loss 0.02211455 - samples/sec: 12.06 - lr: 0.100000\n",
      "2023-02-04 20:07:07,595 epoch 3 - iter 56/75 - loss 0.02157042 - samples/sec: 12.32 - lr: 0.100000\n",
      "2023-02-04 20:07:25,993 epoch 3 - iter 63/75 - loss 0.02132553 - samples/sec: 12.24 - lr: 0.100000\n",
      "2023-02-04 20:07:44,884 epoch 3 - iter 70/75 - loss 0.02109031 - samples/sec: 11.92 - lr: 0.100000\n",
      "2023-02-04 20:07:55,878 ----------------------------------------------------------------------------------------------------\n",
      "2023-02-04 20:07:55,879 EPOCH 3 done: loss 0.0210 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:47<00:00,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-04 20:08:43,576 Evaluating as a multi-label problem: False\n",
      "2023-02-04 20:08:43,589 DEV : loss 0.0417192205786705 - f1-score (micro avg)  0.3921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-04 20:08:44,169 BAD EPOCHS (no improvement): 2\n",
      "2023-02-04 20:08:44,173 ----------------------------------------------------------------------------------------------------\n",
      "2023-02-04 20:09:01,973 epoch 4 - iter 7/75 - loss 0.01910404 - samples/sec: 12.65 - lr: 0.100000\n",
      "2023-02-04 20:09:19,986 epoch 4 - iter 14/75 - loss 0.01906433 - samples/sec: 12.50 - lr: 0.100000\n",
      "2023-02-04 20:09:38,031 epoch 4 - iter 21/75 - loss 0.01803837 - samples/sec: 12.48 - lr: 0.100000\n",
      "2023-02-04 20:09:56,375 epoch 4 - iter 28/75 - loss 0.01780351 - samples/sec: 12.28 - lr: 0.100000\n",
      "2023-02-04 20:10:14,245 epoch 4 - iter 35/75 - loss 0.01770759 - samples/sec: 12.60 - lr: 0.100000\n",
      "2023-02-04 20:10:32,114 epoch 4 - iter 42/75 - loss 0.01769725 - samples/sec: 12.60 - lr: 0.100000\n",
      "2023-02-04 20:10:49,992 epoch 4 - iter 49/75 - loss 0.01773930 - samples/sec: 12.60 - lr: 0.100000\n",
      "2023-02-04 20:11:08,119 epoch 4 - iter 56/75 - loss 0.01817569 - samples/sec: 12.42 - lr: 0.100000\n",
      "2023-02-04 20:11:26,371 epoch 4 - iter 63/75 - loss 0.01809562 - samples/sec: 12.34 - lr: 0.100000\n",
      "2023-02-04 20:11:44,251 epoch 4 - iter 70/75 - loss 0.01802590 - samples/sec: 12.60 - lr: 0.100000\n",
      "2023-02-04 20:11:55,295 ----------------------------------------------------------------------------------------------------\n",
      "2023-02-04 20:11:55,296 EPOCH 4 done: loss 0.0179 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:48<00:00,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-04 20:12:43,715 Evaluating as a multi-label problem: False\n",
      "2023-02-04 20:12:43,730 DEV : loss 0.03290388733148575 - f1-score (micro avg)  0.4811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-04 20:12:44,019 BAD EPOCHS (no improvement): 3\n",
      "2023-02-04 20:12:47,853 ----------------------------------------------------------------------------------------------------\n",
      "2023-02-04 20:12:47,856 loading file classifier/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:49<00:00,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-04 20:13:42,058 Evaluating as a multi-label problem: False\n",
      "2023-02-04 20:13:42,073 0.7166\t0.7166\t0.7166\t0.7166\n",
      "2023-02-04 20:13:42,074 \n",
      "Results:\n",
      "- F-score (micro) 0.7166\n",
      "- F-score (macro) 0.2783\n",
      "- Accuracy 0.7166\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          L3     0.7166    1.0000    0.8349       435\n",
      "          L2     0.0000    0.0000    0.0000       134\n",
      "          L1     0.0000    0.0000    0.0000        38\n",
      "\n",
      "    accuracy                         0.7166       607\n",
      "   macro avg     0.2389    0.3333    0.2783       607\n",
      "weighted avg     0.5136    0.7166    0.5983       607\n",
      "\n",
      "2023-02-04 20:13:42,075 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.7166392092257001,\n",
       " 'dev_score_history': [0.7182866556836903,\n",
       "  0.5485996705107083,\n",
       "  0.39209225700164746,\n",
       "  0.48105436573311366],\n",
       " 'train_loss_history': [0.01384702025031594,\n",
       "  0.02680140213998507,\n",
       "  0.021019572067280827,\n",
       "  0.017904252554552837],\n",
       " 'dev_loss_history': [0.05955692008137703,\n",
       "  0.027069251984357834,\n",
       "  0.0417192205786705,\n",
       "  0.03290388733148575]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "trainer.train('classifier', learning_rate=0.1, mini_batch_size = 32, max_epochs = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('spacy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "049351683cbfcc6592fe172be1f7bdb3ebd27b203ddaf2bcbd9755e634118e44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
