{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain embeddings for words A, B, C and compute embedding for D\n",
    "from flair.data import Sentence\n",
    "\n",
    "def compute_embedding_D(A,B,C,embedding):\n",
    "    # make a sentence from the list of given words\n",
    "    wordsABC_sentence = Sentence(' '.join([A, B, C]))\n",
    "    #print(wordsABC_sentence)\n",
    "    # create embedding of sentence\n",
    "    embedding.embed(wordsABC_sentence)\n",
    "    \n",
    "    # embed each word separately\n",
    "    A_embedded = wordsABC_sentence[0].embedding\n",
    "    B_embedded = wordsABC_sentence[1].embedding\n",
    "    C_embedded = wordsABC_sentence[2].embedding\n",
    "\n",
    "    # derive embedding for D as a arithmetic operation of the known embeddings following the king - man = queen - woman analogy\n",
    "    D_embedding = B_embedded + C_embedded - A_embedded\n",
    "    \n",
    "    return D_embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain embeddings for all english words in Flair\n",
    "from flair import datasets\n",
    "from flair.data import Sentence\n",
    "\n",
    "def get_embedding_english_vocab(embedding):\n",
    "    # get collection of English sentences\n",
    "    dataset = datasets.UD_ENGLISH()\n",
    "    # make a vocabulary dictionaries which has the words as keys\n",
    "    vocab_list = dataset.make_vocab_dictionary().get_items()\n",
    "    # make vocab dictionary keys a sentence object\n",
    "    vocab = Sentence(' '.join(vocab_list))\n",
    "    # embed the sentence object\n",
    "    embedding.embed(vocab)\n",
    "\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the closests matching word\n",
    "from sklearn.metrics.pairwise import cosine_similarity as sim\n",
    "\n",
    "def find_closest_matching_word(D, vocab, ABC):\n",
    "    max_match = -1\n",
    "    for word in vocab:\n",
    "        match = sim([D], [word.embedding.tolist()])[0][0]\n",
    "        if match > max_match and word.text not in ABC:\n",
    "            max_match = match\n",
    "            closest_matching_word = word.text\n",
    "    \n",
    "    return closest_matching_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_A = pn.widgets.TextInput(name='word A', placeholder='Enter a string here...')\n",
    "word_B = pn.widgets.TextInput(name='word B', placeholder='Enter a string here...')\n",
    "word_C = pn.widgets.TextInput(name='word C', placeholder='Enter a string here...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-31 12:01:43,332 Reading data from /homes/cbecht/.flair/datasets/ud_english\n",
      "2023-01-31 12:01:43,333 Train: /homes/cbecht/.flair/datasets/ud_english/en_ewt-ud-train.conllu\n",
      "2023-01-31 12:01:43,334 Dev: /homes/cbecht/.flair/datasets/ud_english/en_ewt-ud-dev.conllu\n",
      "2023-01-31 12:01:43,335 Test: /homes/cbecht/.flair/datasets/ud_english/en_ewt-ud-test.conllu\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import WordEmbeddings\n",
    "\n",
    "@pn.depends(word_A, word_B, word_C)\n",
    "def solve_analogies(A, B, C):\n",
    "    fasttext = WordEmbeddings('crawl')\n",
    "    result = compute_embedding_D(A, B, C, fasttext)\n",
    "    vocab = get_embedding_english_vocab(fasttext)\n",
    "    D = find_closest_matching_word(result, vocab, {A, B, C})\n",
    "    #D = \"bla\"\n",
    "\n",
    "    return f'**{A}** is to **{B}** as **{C}** is to **{D}**'\n",
    "\n",
    "anal_solv = pn.Row(solve_analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sidebar1 = pn.pane.Markdown(\"\"\"\n",
    "#### Selectors for the Analogy solver\n",
    "\"\"\", width=250, margin=(25))\n",
    "\n",
    "Analogy_solver = pn.pane.Markdown(\"\"\"\n",
    "# Analogy Solver\n",
    "All the language models we use up to date are based on word (or document) embeddings. The Hello World of Natural Language Processing is the equation king - man ~ queen - woman.\n",
    "This analogy can be used to make the following statement: Word is to word B as word C is to word D. The following tool allows to enter the words A, B, and C to derive the closest word which is word D.\n",
    "------------\n",
    "\"\"\", width=750, margin=(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching server at http://localhost:33061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bokeh.server.server.Server at 0x7f2156ffc610>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dashboard = pn.template.BootstrapTemplate(title = 'Natural Language Processing Playground', \n",
    "                                          sidebar_width = 250, \n",
    "                                          header_background = '#80b1d3')\n",
    "dashboard.sidebar.append(sidebar1)\n",
    "dashboard.sidebar.append(word_A)\n",
    "dashboard.sidebar.append(word_B)\n",
    "dashboard.sidebar.append(word_C)\n",
    "dashboard.main.append(pn.Row(Analogy_solver, background='WhiteSmoke'))\n",
    "dashboard.main.append(pn.Row(anal_solv))\n",
    "dashboard.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "049351683cbfcc6592fe172be1f7bdb3ebd27b203ddaf2bcbd9755e634118e44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
